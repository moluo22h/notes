# Flink 环境安装指南

## 一、安装前准备
在安装 Flink 之前，需要确保你的系统已经安装Java：

Flink 基于 Java 开发，因此需要安装 Java 8 或更高版本。你可以通过以下命令检查 Java 版本：

```bash
java -version
```
如果未安装 Java，你可以根据自己的操作系统选择合适的安装方式。

## 二、安装步骤

### 1. 下载 Flink

你可以从 Flink 的官方网站（https://flink.apache.org/downloads.html）下载最新版本的 Flink。也可以使用以下命令直接下载：
```bash
wget https://dlcdn.apache.org/flink/flink-1.17.2/flink-1.17.2-bin-scala_2.12.tgz
```
这里以 Flink 1.17.2 版本为例，你可以根据实际需求选择其他版本。

### 2. 解压安装包

下载完成后，使用以下命令解压 Flink 安装包：
```bash
tar -xzf flink-1.17.2-bin-scala_2.12.tgz -C /opt/
```
解压完成后，会在`/opt`目录下生成一个名为 `flink-1.17.2` 的文件夹，进入 Flink 安装目录：

```bash
cd /opt/flink-1.17.2
```

### 3. 配置环境变量
为了方便使用 Flink 命令，需要将 Flink 的 `bin` 目录添加到系统的环境变量中。打开 `/etc/profile` 文件：
```bash
vi /etc/profile
```
在文件末尾添加以下内容：
```bash
export FLINK_HOME=/opt/flink-1.17.2
export PATH=$PATH:$FLINK_HOME/bin
```
将 `/opt/flink-1.17.2` 替换为你实际的 Flink 安装路径。保存并退出文件后，执行以下命令使环境变量生效：

```bash
source /etc/profile
```

## 三、启动Flink

Flink支持多种启动方式，常见的有单机模式、集群模式（Standalone、YARN、Kubernetes）等，请根据使用场景选择合适的启动方式

### 单机模式

单机模式主要用于本地开发和测试，它在单个 JVM 进程中模拟 Flink 集群的运行。启动步骤

1. **进入 Flink 安装目录**：打开终端，使用 `cd` 命令进入你安装 Flink 的目录。

   ```bash
   cd /opt/flink-1.17.2
   ```

2. **启动 Flink 集群**：执行以下命令启动单机模式的 Flink 集群。

   ```bash
   # ./bin/start-cluster.sh
   Starting cluster.
   Starting standalonesession daemon on host hadoop.
   Starting taskexecutor daemon on host hadoop.
   ```

3. **验证启动**：启动成功后，可通过`jps`查看进程

   ```bash
   # jps
   2965 StandaloneSessionClusterEntrypoint
   3257 TaskManagerRunner
   ```

   也可通过访问 `http://192.168.10.50:8081` 查看 Flink 的 Web UI，页面会显示集群状态信息。

   ![image-20250409154554344](D:\user\person\notes\编程学习\大数据\Flink\assets\image-20250409154554344.png)

4. **停止集群**：当不再需要时，执行以下命令停止集群。

   ```bash
   ./bin/stop-cluster.sh
   ```

### 集群模式（Standalone）

Standalone 是 Flink 自带的集群模式，可手动管理资源。

1. **规划机器**：在Flink集群中，Master节点上会运行JobManager进程，Slave节点上会运行TaskManager进程。下面我们以一主两从来进行演示

   | 节点类型 | 主机名 | IP            |
   | -------- | ------ | ------------- |
   | Master   | master | 192.168.10.50 |
   | Slave    | slave1 | 192.168.10.51 |
   | Slave    | slave2 | 192.168.10.52 |

2. **配置文件修改**：进入 Flink 安装目录下的 `conf` 文件夹，修改 `masters`、`workers` 和 `flink-conf.yaml` 文件。

    - 在`masters` 文件中指定 JobManager 的地址和端口。默认值如下，根据实际情况修改

      ```bash
      192.168.10.50:8081
      ```

    - 在`workers` 文件中指定 TaskManager 所在的主机名或 IP 地址。如果有多个 TaskManager，可以每行添加一个地址。默认值如下，根据实际情况修改，

      ```bash
      192.168.10.51
      192.168.10.52
      ```

    - `flink-conf.yaml` 可调整内存分配、并行度等全局配置。

      ```bash
      jobmanager.rpc.address: 192.168.10.50
      ```

      > 扩展：常见的配置项包括：
      >
      > | 参数                            | **解释**                                              |
      > | ------------------------------- | ----------------------------------------------------- |
      > | jobmanager.memory.process.size  | 主节点可用内存大小                                    |
      > | taskmanager.memory.process.size | 从节点可用内存大小                                    |
      > | taskmanager.numberOfTaskSlots   | 从节点可以启动的进程数量，建议设置为从节可用的cpu数量 |
      > | parallelism.default             | Flink任务的默认并行度                                 |

3. **分发文件**：将修改后的配置文件分发到集群中的所有节点。

    ```bash
    scp -rq /opt/flink-1.17.2 192.168.10.51:/opt/
    scp -rq /opt/flink-1.17.2 192.168.10.52:/opt/
    ```

4. **启动集群**：在主节点上执行以下命令启动集群。

    ```bash
    ./bin/start-cluster.sh
    ```

5. **验证启动**：启动成功后，可通过`jps`查看`master`、`slave1`、`slave2` 节点进程

   ```bash
   [root@master]# jps
   2965 StandaloneSessionClusterEntrypoint
   
   [root@slave1]# jps
   3218 TaskManagerRunner
   
   [root@slave2]# jps
   3257 TaskManagerRunner
   ```

   也可通过访问 JobManager 地址 `http://192.168.10.50:8081` 查看 Flink 的 Web UI，页面会显示集群状态信息。

6. **停止集群**：同样在主节点上执行以下命令停止集群。

   ```bash
   ./bin/stop-cluster.sh
   ```

### 集群模式（YARN）

YARN是 Hadoop 中的资源管理系统，Flink 可借助 YARN 管理资源。Flink on Yarn具有两种方式：

- 方式一：在YARN中预先初始化一个Flink集群，占用YARN中固定的资源。

  该Flink集群常驻YARN 中，所有的Flink任务都提交到这里。这种方式的缺点在于不管有没有Flink任务执行，Flink集群都会独占系统资源，除非手动停止。如果YARN中给Flink集群分配的资源耗尽，只能等待YARN中的一个作业执行完成释放资源才能正常提交下一个Flink作业。这种方式适合小规模、短时间计算任务。

- 方式二：每次提交Flink任务时单独向YARN申请资源。

  即每次都在YARN上创建一个新的Flink集群，任务执行完成后Flink集群终止，不再占用机器资源。这样不同的Flink任务之间相互独立互不影响。这种方式能够使得资源利用最大化，适合长时间、大规模计算任务。

#### 前置准备

在运行集群模式（YARN）之前，无论使用哪种方式，都需要先运行Hadoop集群：

如果未安装 Hadoop，你可以根据自己的操作系统选择合适的安装方式。

同时**配置环境**：确保系统已安装并配置好 Hadoop YARN，同时将 Hadoop 的HADOOP_CLASSPATH配置添加到 `/etc/profile` 中。

```bash
export HADOOP_CLASSPATH=`${HADOOP_HOME}/bin/hadoop classpath`
```

#### 方式一

1. **启动会话模式**：在会话模式下，Flink 集群在 YARN 上持续运行，可提交多个作业。

   ```bash
   ./bin/yarn-session.sh -n 2 -jm 1024 -tm 1024 -d
   ```

   其中，`-n` 表示 TaskManager 的数量，`-jm` 表示 JobManager 的内存大小，`-tm` 表示每个 TaskManager 的内存大小，-d：设置后台执行

2. **验证启动**：启动成功后，通过在yarn控制台，即hadoop集群管理页面查看是否有flink任务成功运行

   也可通过访问 `http://192.168.10.50:34248` 查看 Flink 的 Web UI，页面会显示集群状态信息。

3. **启动作业模式**：作业模式下，每个 Flink 作业都会启动一个独立的集群。

   ```bash
   bin/flink run ./examples/batch/wordcount.jar
   ```
4. **停止集群**：可使用yarn application -kill 停止集群

   ```bash
   yarn application -kill application_21939794917_0001
   ```

#### 方式二

这种方式很简单，就是在提交flink任务时同时创建flink集群

1. **启动作业模式**：作业模式下，每个 Flink 作业都会启动一个独立的集群。

   ```bash
   ./bin/flink run -m yarn-cluster -yn 2 -yjm 1024 -ytm 1024 examples/streaming/WordCount.jar
   ```

2. **停止集群**：会话模式下，在终端按 `Ctrl + C` 停止；作业模式下，作业完成后集群自动释放。

#### 启动historyserver

为了flink停止后仍然能查看到日志，可以启动historyserver

1. 启动hadoop的historyserver

2. 修改`flink-conf.yaml`配置

   ```bash
   # 指定由 JobManager 归档的作业信息所存放的目录
   jobmanager.archive.fs.dir: hdfs:///192.168.10.50:9000/completed-jobs/
   
   # History Server 所绑定的 IP
   historyserver.web.address: 192.168.10.50
   
   # History Server 所监听的端口号（默认 8082）
   historyserver.web.port: 8082
   
   # 指定 History Server 扫描哪些归档目录，多个目录使用逗号分隔
   historyserver.archive.fs.dir: hdfs://192.168.10.50:9000/completed-jobs/
   
   # 指定 History Server 间隔多少毫秒扫描一次归档目录
   historyserver.archive.fs.refresh-interval: 10000
   ```

3. 使用以下命令启动服务器

   ```bash
   bin/historyserver.sh start
   ```

4. 验证historyserver是否启动成功

   在提交任务并取消后，可以在 `http://192.168.10.50:8082` 查看历史完成任务的状态和统计信息：

5. 停止historyserver

   ```bash
   bin/historyserver.sh stop
   ```

## 四、验证安装

为了验证 Flink 是否安装成功，可以运行一个简单的示例程序。在 Flink 安装目录下，执行以下命令：
```bash
./bin/flink run examples/streaming/WordCount.jar

tail log/flink-*-taskexecutor-*.out
  (nymph,1)
  (in,3)
  (thy,1)
  (orisons,1)
  (be,4)
  (all,2)
  (my,1)
  (sins,1)
  (remember,1)
  (d,4)
```
该命令会运行一个 WordCount 示例程序，对输入的文本进行单词计数。如果程序正常运行并输出结果，说明 Flink 安装成功。

## 五、常见问题

### 问题一：Flink Web UI 无法访问

当你启动 Flink 集群后，发现无法通过浏览器访问 Flink Web UI 时，可能是由于网络配置、防火墙设置或端口占用等问题导致的。以下是一些常见的解决方法。

1. 禁用防火墙

   ```bash
   service iptables status # 确认防火墙状态为 inactive
   ```

2. 检查端口占用情况

   确保 Flink 使用的端口（默认8081）未被其他进程占用。

   ```bash
   lsof -i:8081 # 确认端口处于 LISTEN 状态
   ```

3. 使用 `vi conf/flink-conf.yaml` 命令修改 Flink 配置文件中的 `rest.bind-address` 配置项，将其设置为 `0.0.0.0`。

   ```bash
   rest.bind-address: 0.0.0.0
   ```

   修改后，重启 Flink 服务。

   ```bash
   ./bin/stop-cluster.sh
   ./bin/start-cluster.sh
   ```

通过以上步骤，你应该能够成功访问 Flink Web UI。如果问题仍然存在，请检查网络连接和其他可能的配置问题。

## 六、总结

通过以上步骤，你就可以成功安装并启动 Flink。在实际使用中，你可以根据具体的业务需求对 Flink 进行进一步的配置和开发。 

## 参考文档

[本地模式安装 | Apache Flink](https://nightlies.apache.org/flink/flink-docs-release-1.17/zh/docs/try-flink/local_installation/)

[Flink教程(1)-集群安装与部署_flink1.19环境搭建-CSDN博客](https://blog.csdn.net/hellozpc/article/details/109413465)