# Hive的基本使用



## Hive 数据类型

- 基本数据类型：int、float、double、string、boolean、bigint等
- 复杂类型：array、map、struct

## Hive 分区

Hive将海量数据按某几个字段进行分区，查询时不必加载全部数据

分区对应到HDFS就是HDFS的目录

分区分为静态分区和动态分区两种

## Hive语法

```hive
CREATE TABLE table_name(...)ROW FORMAT DELIMITED FIELDS TERMINATED BY "'vt" STORE AS TEXTFILE

SELECT* from table_name

ALTER TABLE table_name RENAME TO new_table_name
```

创建表示例

```hive
CREATE TABLE test(
user_id string,
user_name string,
hobby array<string>,
scores map<string,integer>
)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY '|'
COLLECTION ITEMS TERMINATED BY ','
MAP KEYS TERMINATED BY ':'
LINES TERMINATED BY '\n';
```

加载数据

```hive
load data local inpath '/root/test.csv' overwrite into table test;
```

查询数据

```hive
select * from test;
select * from test where user_name=='Tom';
```

选择数据库

```hive
use hive_test;
```

查询表集合

```hive
show tables;
```

删除表

```hive
drop table test_table;
```



## Hive执行语句方式

方式一：通过hive

```bash
hive
hive -e "show databases;"
hive -f test.sql
```

方式二：通过beeline

```bash
beeline
```

## **Hive 数据模型**
### 内部表

和传统数据库的Table概念类似，对应HDFS上存储目录，删除表时，删除元数据和表数据

```hive
CREATE TABLE table_name(...)ROW FORMAT DELIMITED FIELDS TERMINATED BY "'vt" STORE AS TEXTFILE
```

### 外部表

指向已经存在的HDFS数据，删除时只删除元数据信息。

```hive
CREATE external TABLE table_name(...)ROW FORMAT DELIMITED FIELDS TERMINATED BY "'vt" STORE AS TEXTFILE
```

### 分区表

分区表是表创建的时候需要指定分区字段，分区字段与普通字段的区别：分区字段会在HDF5表目录下生成一个分区字段名称的目录，而非普通字段则不会。查询的时候可以当成普通字段来使用，一般不直接和业务直接相关。

通过`partitioned by`指定分区

```hive
CREATE TABLE partition_test(
user_id string,
user_name string,
hobby array<string>,
scores map<string,integer>
)
partitioned by (create_time string)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY '|'
COLLECTION ITEMS TERMINATED BY ','
MAP KEYS TERMINATED BY ':'
LINES TERMINATED BY '\n';
```

加载数据到分区表时，通过`partition`指定分区

```bash
load data local inpath '/root/test.csv' overwrite into table partition_test partition(create_time='201911');
```

查询指定的分区的数据

```bash
select * from partition_test where create_time=='201911';
```

### 分桶表

将内部表和外部表进一步组织成桶表，可以将表的存储通过Hash算法进行进一步分解或不同的文件存储。

通过`clustered by`指定分桶

```hive
CREATE TABLE bucket_test(
user_id string,
user_name string,
hobby array<string>,
scores map<string,integer>
)
clustered by (user_name) sorted by (user_name) into 2 buckets 
ROW FORMAT DELIMITED
FIELDS TERMINATED BY '|'
COLLECTION ITEMS TERMINATED BY ','
MAP KEYS TERMINATED BY ':'
LINES TERMINATED BY '\n';
```

加载数据到分桶表时

```bash
load data local inpath '/root/test.csv' overwrite into table bucket_test;
```

抽样

```bash
select * from bucket_test TABLESAMPLE(bucket 1 out of 2 on user_name);
```

## Hive的函数

### Hive内置函数

- 字符串类型：concat、substr、upper、lower

- 时间类型：year、month、day

- 复杂类型：size、get_json_object

### Hive自定义函数

#### UDF类型

Hive中有3种UDF类型：

UDF：用来处理输入一行，输出一行的操作，类似Map操作

UDAF：自定义聚合函数，用来处理输入多行，输出一行的操作，类似Reduce操作

UDTF：自定义表产生函数，用来处理输入一行，输出多行的操作
#### UDF注册

开发了UDF之后，我们需要将UDF注册到Hive中才能使用，那么如何进行函数的注册呢？

Hive中对于UDF的注册分为两种，一种是临时注册，一种是永久注册。

顾名思义，临时注册即当前session中生效，而永久注册是一直生效。

临时注册

```bash
#导入jar包
#部署到hive的lib下，进入hive的交互式环境
hive
#添加jar到hive的classpath，或者add jar时指定全路径
add jar hive-udf-test-1.0-SNAPSHOT.jar
#注册临时函数
create temporary function UDF_NAME AS 'com.imoc.naga.TESTUOF';
#删除注册函数
drop temporary function UDF_NAME;
```

永久注册

```bash
#永久注册需要将jar包放到HDFS上，避免无法找到
create function UDF_NAME as 'com.imoc.naga.TESTUOF' using jar 'hdfs://hive_udf/hive-udf-test-1.0-SNAPSHOT.jar';
#删除注册函数
drop function UDF_NAME;
```

## Hive存储格式

|               | 优点                   | 缺点               |
| ------------- | ---------------------- | ------------------ |
| TextFile      | 简单、方便查看         | 不支持分片         |
| Sequence File | 可压缩、可分割         | 需要合并、不易查看 |
| OrcFile       | 分片、按列查询、速度快 | 不易查看           |

 
