## Spark简介

Spark是一个高性能的、多用途的开源集群计算框架

Spark是Apache基金会最重要的项目之一，是现在大数据领域最热门的大数据计算平台之一

Spark不仅具备Hadoop MapReduce的优点，且解决了MapReduce的缺陷

![image-20240722152937107](D:\user\person\notes\编程学习\大数据\大数据平台\assets\image-20240722152937107.png)

## Spark优势

支持多种数据源，如HDFS、S3、JDBC等

支持多种运行模式，如Local、Standalone、Cluster

包含多个完整强大的组件，如SparkCore、SparkSql、SparkML

多语言且支持交互式，支持Scala、Java、Python、R

很好的兼容Hadoop生态，能够访问HDFS，支持on Yarn运行

运行速度快，计算效率高，中间结果不落地，在内存中进行，通过构建DAG图，即使某一步失败也能很快重新计算

## Spark组件



![image-20240722153202996](D:\user\person\notes\编程学习\大数据\大数据平台\assets\image-20240722153202996.png)

## Spark的架构

![image-20240722153830837](D:\user\person\notes\编程学习\大数据\大数据平台\assets\image-20240722153830837.png)

Spark运行架构包括Cluster Manager、Driver和Executor

- Driver: Spark应用的任务控制节点

- Executor: Spark应用的任务的执行进程

- Cluster Manager: Spark任务的资源管理器，如最常用的Yarn

Executor内有线程池，通过多线程执行相关任务

Task的中间结果直接写入到内存，有效减少IO开销

## Spark的任务运行

![image-20240722154322516](D:\user\person\notes\编程学习\大数据\大数据平台\assets\image-20240722154322516.png)

Application:应用,即我们提交到Spark的执行程序

Job: Spark中对RDD进行Action操作所产生的RDD处理流程

Stage:阶段,一个Job会切分成多个Stage,各个Stage之间按照顺序执行

一个Spark Application包含一个Driver和多个Job

一个Job包含多个Stage，一个Stage又包含多个Task



## Spark的执行流程



![image-20240722154647154](D:\user\person\notes\编程学习\大数据\大数据平台\assets\image-20240722154647154.png)

> 名词解释：
>
> SparkContext:整个应用的上下文，控制应用的生命周期
>
> RDD：弹性分布式数据集（Resilient Distributed Dataset）
>
> DAG：是Directed Acyclic Graph（有向无环图）的简称，反映RDD之间的依赖关系



提交应用后，Driver会创建SparkContext实例，申请资源

ClusterManager分配资源，启动Executor进程，Executor向Driver注册并申请任务

SparkContext生成DAG图通过DAGScheduler解析，生成多个Stage并通过TaskScheduler分配到各个Executor执行

## Spark执行特点

Job的执行过程与资源管理器无关，资源管理器只分配资源

Executor含有线程池，以多线程的方式提高任务的执行效率

每个Task产生的结果会放入内存，避免了大量的IO开销