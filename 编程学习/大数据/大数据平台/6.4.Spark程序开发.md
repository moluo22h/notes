# Spark程序开发

## 使用java开发

1. 开发spark程序

2. 通过如下命令加载并执行

   ```bash
   $ spark-submit --master yarn --class demo.spark.WordCount sparktest-1.0-SNAPSHOT.jar /sparktest /sparkout
   ```

## SparkSQL

### 背景：SQL on Hadoop

Hive的出现让技术人员可以通过类SQL的方式对批量数据进行查询，而不用开发MapReduce程序

MapReduce计算过程中大量的中间结果磁盘落地使运行效率较低

为了提高SQL on Hadoop的效率，各大工具应运而生，比如Shark、Impala等

### SparkSQL简介

SparkSQL是Spark为处理结构化数据而引入的模块，前身是Shark

SparkSQL提供了一个DataFrame的编程抽象，底层依然为RDD

SparkSQL是一个分布式的SQL查询引擎，支持标准SQL和HSQL

### DataFrame简介

类似于关系型数据库的table，是分布式数据集，可以认为是有Schema的RDD 

一个DataFrame可以注册成一张表，支持sql操作和丰富的函数

有丰富的创建方式，支持Hive、JDBC、结构化文件、RDD等，

可以与pandas的dataframe相互转换

### SparkSQL的使用

后期补充

### Spark自定义UDF

后期补充

### Spark程序开发原则与基础优化

#### Spark常见问题

Spark本身的内存和并行度设置有问题，未进行数据序列化

对同一数据源多次创建RDD，未正确复用和持久化RDD

错误的使用算子，造成多次shuffle操作

#### Spark常见调优策略

设置适当的Executor num、memory、core等参数

使用Kryo优化序列化性能，优化数据结构

避免对同一数据源创建RDD

尽可能的复用同一个RDD

对多次使用的RDD进行持久化

对外部大变量进行广播

尽量避免使用shuffle类算子

使用map-side预聚合的shuffle操作

资源允许的情况下多使用Partitions操作

#### Spark持久化级别

| 持久化级别          | 含义                                                         |
| ------------------- | ------------------------------------------------------------ |
| MEMORY_ONLY         | 使用未序列化的Java对象格式，将数据保存在内存中。资源不足则不持久化 |
| MEMORY_AND_DISK     | 使用未序列化的Java对象格式，优先将数据保存在内存中。资源不足则将数据写入磁盘文件 |
| MEMORY_ONLY_SER     | 将RDD中的数据进行序列化，持久化到内存，资源不足则不持久化    |
| MEMORY_AND_DISK_SER | 将RDD中的数据进行序列化，持久化到内存，资源不足则将数据写入磁盘文件 |

### Spark数据倾斜调优

#### 定位导致数据倾斜的代码

复制配置模板

```bash
cp spark-defaults.conf.template spark-default.conf
```

编辑`spark-default.conf`

```bash
spark.eventLog.enabled    true
Spark.eventLog.dir        hdfs://localhost:9000/sparklog
```

执行

```bash
$ start-history-server.sh hdfs://localhost:9000/sparklog
```

浏览器访问http://{ip}:18080



#### Spark调优策略

定位导致数据倾斜的代码

对倾斜的数据进行预处理，或者忽略导致倾斜的key

丰富计算逻辑，进行局部聚合+全局聚合

将reduce join转化为map join

多种方式结合使用，提高spark程序执行效率

| 参数                           | 功能                                                  |
| ------------------------------ | ----------------------------------------------------- |
| spark.sql.shuffle.partitions   | 提高shuffle并行度                                     |
| spark.reducer.maxSizeInFlight  | 设置shuffle read task的buffer缓冲大小                 |
| spark.shuffle.manager          | 设置ShuffleManager的类型，hash、sort和tungsten-sort   |
| spark.shuffle.memoryFraction   | Executor分配给shuffle read task进行聚合操作的内存比例 |
| spark.shuffle.consolidateFiles | 合并shuffle write的输出文件                           |