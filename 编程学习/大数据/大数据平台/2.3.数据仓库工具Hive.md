# Hive

## Hive简介

- Hive是基于Hadoop的数据库工具，提供类SQL语法
- 以MR作为计算引擎、HDFS作为存储系统，提供超大数据集 的计算/扩展能力
- Hive是将数据映射成数据库和一张张的表，库和表的元数据信 息一般存在关系型数据库

## Hive架构图

![image-20240531114034256](D:\user\person\notes\编程学习\大数据\大数据平台\assets\image-20240531114034256.png)

- Hive有多种接口供客户端使用，其中包括**Thrift接口**、**数据库接口**、**命令行接口**和**Web接口**。
  - 数据库接口包括**ODBC**（Open Database Connectivity，开放数据库连接）和**JDBC**（Java DataBase Connectivity，Java数据库连接）。
  - 客户端通过Thrift接口及数据库接口访问Hive时，用户需连接到Hive Server，通过Hive Server与Driver通信。命令行接口CLI是和Hive交互的最简单方式，可以直接调用Driver进行工作。CLI只能支持单用户，可用于管理员工作，但不适用于高并发的生产环境。用户也可使用Web接口通过浏览器直接访问Driver并调用其进行工作。

- **Hive Server**作为JDBC和ODBC的服务端，提供Thrift接口，可以将Hive和其他应用程序集成起来。Hive Server基于Thrift软件开发，又被称为Thrift Server。Hive Server有两个版本，包括HiveServer和HiveServer2。HiveServer2本身自带了一个命令行工具BeeLine，方便用户对HiveServer2进行管
- **MetaStore**存储Hive的元数据，Hive的元数据包括表的名字、表的属性、表的列和分区及其属性、表的数据所在目录等。元数据被存储在单独的关系数据库中，常用的数据库有MySQL和Apache Derby（Java数据库）。MetaStore提供Thrift界面供用户查询和管理元数据。
- **Driver**接收客户端发来的请求，管理HiveQL命令执行的生命周期，并贯穿Hive任务整个执行期间。Driver中有**编译器**（Compiler）、**优化器**（Optimizer）和**执行器**（Executor）三个角色。Compiler编译HiveQL并将其转化为一系列相互依赖的Map/Reduce任务。Optimizer分为逻辑优化器和物理优化器，分别对HiveQL生成的执行计划和MapReduce任务进行优化。Executor按照任务的依赖关系分别执行Map/Reduce任务。

## Hive vs Hadoop

- Hive数据存储： Hive的数据是存储在HDFS上的， Hive的库和表是对HDFS上数据的映射
- Hive元数据存储： 元数据存储一般在外部关系库(Mysql) ,与Presto Impala等共享
- Hive语句的执行过程： 将HQL转换为MapReduce任务运行



## Hive VS 数据库

|          | Hive      | RDBMS    |
| -------- | --------- | -------- |
| 查询语言 | HQL       | SQL      |
| 数据存储 | HDFS      | 本地磁盘 |
| 索引     | 无        | 有       |
| 执行     | MapReduce | Executor |
| 执行延时 | 高        | 低       |
| 数据规模 | 大        | 小       |