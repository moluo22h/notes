# Hive安装

## 使用linux安装

1. 下载hive并解压，下载地址：https://downloads.apache.org/hive/

   ```bash
   wget https://downloads.apache.org/hive/hive-3.1.3/apache-hive-3.1.3-bin.tar.gz
   tar zvxf apache-hive-3.1.3-bin.tar.gz
   ```

   > 提示：查询hive所支持的hadoop版本，可通过如下地址：https://hive.apache.org/general/downloads/

2. 通过`vi ~/.bash_profile`命令添加环境变量，添加如下内容，添加完成后通过`source ~/.bash_profile`命令加载环境变量

   ```bash
   export HIVE_HOME=/root/apache-hive-3.1.3-bin
   export PATH=$HIVE_HOME/bin:$PATH
   ```

3. 修改hive相关配置，配置位于conf目录下

   修改`hive-env.sh`, 修改前通过`cp hive-env.sh.template hive-env.sh`命令对模板进行复制，然后添加如下配置

   ```bash
   export JAVA_HOME=/root/jdk1.8.0_191
   export HADOOP_HOME=/root/hadoop-2.8.5
   ```

   修改`hive-site.xml`, 修改前通过`cp hive-default.xml.template hive-site.xml`命令对模板进行复制

   ```bash
   <?xml version="1.0" encoding="UTF-8" standalone="no"?>
   <?xml-stylesheet type="text/xsl" href="configuration.xsl"?><!--
      Licensed to the Apache Software Foundation (ASF) under one or more
      contributor license agreements.  See the NOTICE file distributed with
      this work for additional information regarding copyright ownership.
      The ASF licenses this file to You under the Apache License, Version 2.0
      (the "License"); you may not use this file except in compliance with
      the License.  You may obtain a copy of the License at
      http://www.apache.org/licenses/LICENSE-2.0
      Unless required by applicable law or agreed to in writing, software
      distributed under the License is distributed on an "AS IS" BASIS,
      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
      See the License for the specific language governing permissions and
      limitations under the License.
   -->
   <configuration>
           # 下载mysql驱动放置在hive的lib目录下，并添加mysql的连接地址
           <property>
                   <name>javax.jdo.option.ConnectionURL</name>
                   <value>jdbc:mysql://localhost:3306/hive?createDatabaseIfNotExist=true</value>
           </property>
           <property>
                   <name>javax.jdo.option.ConnectionDriverName</name>
                   <value>com.mysql.cj.jdbc.Driver</value>
           </property>
           <property>
                   <name>javax.jdo.option.ConnectionUserName</name>
                   <value>root</value>
           </property>
           <property>
                   <name>javax.jdo.option.ConnectionPassword</name>
                   <value>123456</value>
           </property>
           
           # 添加一系列metaStore的相关地址
           <property>
                   <name>hive.metastore.warehouse.dir</name>
                   <value>/hive/warehouse</value>
           </property>
           <property>
                   <name>hive.exec.scratchdir</name>
                   <value>/hive/tmp</value>
           </property>
           <property>
                   <name>hive.querylog.location</name>
                   <value>/hive/log</value>
           </property>
   </configuration>
   ```

   修改`hive-log4j2.properties`, 修改前通过`cp hive-log4j2.properties.template hive-log4j2.properties`命令对模板进行复制

   ```bash
   ```

   修改`beeline-log4j2.properties`, 修改前通过`cp beeline-log4j2.properties.template beeline-log4j2.properties`命令对模板进行复制

   ```bash
   ```

4. 在hdfs中创建hive相关的目录

   ```bash
   hdfs dfs -mkdir /hive
   hdfs dfs -mkdir /hive/tmp
   hdfs dfs -mkdir /hive/log
   hdfs dfs -mkdir /hive/warehouse
   
   hdfs dfs -chmod 777 /hive/tmp
   hdfs dfs -chmod 777 /hive/log
   hdfs dfs -chmod 777 /hive/warehouse
   ```

5. 在mysql中初始化数据库

   ```bash
   ./schematool --dbType mysql --initSchema
   ```

   > 提示：若报错java.lang.NoSuchMethodError: com.google.common.base.Preconditions.checkArgument，请参考https://blog.csdn.net/qq_44766883/article/details/108582781
   >
   > ```bash
   > rm /opt/apache-hive-3.1.3-bin/lib/guava-19.0.jar
   > cp /opt/hadoop-3.2.4/share/hadoop/common/lib/guava-27.0-jre.jar /opt/apache-hive-3.1.3-bin/lib/
   > ```

6. 启动hive-metastore

   ```bash
   hive --service metastore &
   ```

   > 通过`jps`命令，看见RunJar则说明启动成功。

7. 连接hive

   通过hive命令连接客户端

   ```bash
   hive
   show databases;
   ```

8. 启动hive-server2

   ```bash
   ./hiveserver2 &
   ```

9. 连接hive-server2

   ```bash
   ./beeline -u jdbc:hive2://localhost:10000
   show databases;
   ```

   > 提示：若报如下错误，请参考：https://blog.csdn.net/imudges_Zy/article/details/89789947
   >
   > ```bash
   > Error: Could not open client transport with JDBC Uri: jdbc:hive2://localhost:10000: Failed to open new session: java.lang.RuntimeException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.authorize.AuthorizationException): User: root is not allowed to impersonate anonymous (state=08S01,code=0)
   > ```
   >
   > 修改hadoop 配置文件 etc/hadoop/core-site.xml,加入如下配置项
   >
   > ```bash
   > <property>
   >     <name>hadoop.proxyuser.root.hosts</name>
   >     <value>*</value>
   > </property>
   > <property>
   >     <name>hadoop.proxyuser.root.groups</name>
   >     <value>*</value>
   > </property>
   > ```
   
   安装完成

## 使用Docker安装Hive

1. 选择要安装的Hive版本

   ```bash
   export HIVE_VERSION=4.0.0
   ```

2. 启动`HiveServer2`，内嵌一个`Metastore`

   ```bash
   docker run -d -p 10000:10000 -p 10002:10002 --env SERVICE_NAME=hiveserver2 --name hive4 apache/hive:${HIVE_VERSION}
   ```

   > 提示：若要使用单独的`Metastore`，可使用如下命令单独启动一个容器
   >
   > ```bash
   > docker run -d -p 9083:9083 --env SERVICE_NAME=metastore --name metastore-standalone apache/hive:${HIVE_VERSION}
   > ```

3. 浏览器访问 http://localhost:10002/，出现HiveServer2 Web页面则说明安装成功

   ![image-20240606151446931](D:\user\person\notes\编程学习\大数据\大数据平台\assets\image-20240606151446931.png)

4. 连接到beeline

   ```bash
   docker exec -it hiveserver2 beeline -u 'jdbc:hive2://hiveserver2:10000/'
   ```

## 参考文档

[apache/hive - Docker Image | Docker Hub](https://hubgw.docker.com/r/apache/hive)

[QuickStarted (apache.org)](https://hive.apache.org/development/quickstart/)

[（超详细）大数据技术之Hive的实战_hive实战-CSDN博客](https://blog.csdn.net/JunLeon/article/details/121606429)

