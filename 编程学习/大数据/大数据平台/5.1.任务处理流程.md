## 任务处理现状

搭建Hadoop集群，实现了离线数仓的基础架构

编写HQL定时对数据进行计算，生成T+1的离线数据

不同的任务编写成不同的HQL文件，通过Crontab进行调度

安排几十个计算的先后顺序，避免顺序颠倒导致计算错误

一个任务失败，后续任务全部等待，效率很低

任务太多，串行执行时间太长

## 任务处理场景

1. 原始数据为业务数据库 or FTP存储的文件类数据

2. 通过Shell脚本或者Hadoop工具，将数据存储到HDFS
3. 通过MapReduce任务对HDFS上的原始数据进行转换，以分区表的形式存储到多张Hive表
4. 对Hive中多个表的数据进行JOIN处理，得到一个明细数据Hive大表
5. 将明细数据进行复杂的统计分析，得到结果报表信息
6. 将统计分析得到的结果数据同步到业务系统中，供业务调用使用

## 任务处理需求

分解计算任务，支持shell脚本程序，java程序，mapreduce程序、hive脚本等

各任务单元之间存在时间先后及前后依赖关系，前置任务失败，后续依赖任务不执行

很好地对任务进行编排组织复杂执行计划，定时触发计算任务，任务失败进行报警

