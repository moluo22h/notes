# Sqoop快速入门

Sqoop是一款用于在Hadoop和关系型数据库之间进行数据传输的工具。它可以将数据从关系型数据库中导入到Hadoop的HDFS、Hive、HBase等数据仓库中，也可以将数据从Hadoop中导出到关系型数据库中。

Sqoop的优势在于它能够处理大量的数据，并且可以自动化地完成数据的导入导出操作。使用Sqoop可以将数据从一个数据库中导出到一个Hadoop集群中，然后对数据进行处理和分析。同时，Sqoop还支持并行传输，可以充分利用集群资源，提高数据传输的效率。

## 使用方式

Sqoop的使用非常简单，只需要几个命令就可以完成数据的导入导出操作。

### 导入数据

要将MySQL数据库中的表数据导入到HDFS中，可以使用以下命令：

```bash
sqoop import \
--connect jdbc:mysql://localhost:3306/test \
--username root \
--password 123456 \
--table user \
--m 1 \
--target-dir /user/hadoop/mydata \
--delete-target-dir \
--fields-terminated-by '\t' \
--lines-terminated-by '\n'
```

> 其中，
>
> `--connect`参数指定了要连接的数据库的JDBC URL；
>
> `--username`和`--password`参数指定了连接数据库所使用的用户名和密码；
>
> `--table`参数指定了要导入的表名；
>
> `--m`参数指定了使用的MapReduce作业的数量；
>
> `--target-dir`参数指定了HDFS中的目标目录；
>
> `--delete-target-dir`参数指定了在导入之前是否删除目标目录中的数据；
>
> `--fields-terminated-by`和`--lines-terminated-by`参数指定了字段和行的分隔符。

### 导出数据

同样地，如果要将HDFS中的数据导出到MySQL数据库中，可以使用以下命令：

```bash
sqoop export \
--connect jdbc:mysql://localhost:3306/test \
--username root \
--password 123456 \
--table user \
--export-dir /user/hadoop/mydata \
--input-fields-terminated-by '\t' \
--input-lines-terminated-by '\n'
```

> 其中，
>
> `--connect`参数指定了要连接的数据库的JDBC URL；
>
> `--username`和`--password`参数指定了连接数据库所使用的用户名和密码；
>
> `--table`参数指定了要导出的表名；
>
> `--export-dir`参数指定了HDFS中的源目录；
>
> `--input-fields-terminated-by`和`--input-lines-terminated-by`参数指定了字段和行的分隔符。

## 常见问题

### 驱动缺失

```bash
java.lang.RuntimeException: Could not load db driver class: com.mysql.jdbc.Driver
        at org.apache.sqoop.manager.SqlManager.makeConnection(SqlManager.java:875)
        at org.apache.sqoop.manager.GenericJdbcManager.getConnection(GenericJdbcManager.java:59)
        at org.apache.sqoop.manager.SqlManager.execute(SqlManager.java:763)
        at org.apache.sqoop.manager.SqlManager.execute(SqlManager.java:786)
        at org.apache.sqoop.manager.SqlManager.getColumnInfoForRawQuery(SqlManager.java:289)
        at org.apache.sqoop.manager.SqlManager.getColumnTypesForRawQuery(SqlManager.java:260)
        at org.apache.sqoop.manager.SqlManager.getColumnTypes(SqlManager.java:246)
        at org.apache.sqoop.manager.ConnManager.getColumnTypes(ConnManager.java:327)
        at org.apache.sqoop.orm.ClassWriter.getColumnTypes(ClassWriter.java:1872)
        at org.apache.sqoop.orm.ClassWriter.generate(ClassWriter.java:1671)
        at org.apache.sqoop.tool.CodeGenTool.generateORM(CodeGenTool.java:106)
        at org.apache.sqoop.tool.ImportTool.importTable(ImportTool.java:501)
        at org.apache.sqoop.tool.ImportTool.run(ImportTool.java:628)
        at org.apache.sqoop.Sqoop.run(Sqoop.java:147)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:82)
        at org.apache.sqoop.Sqoop.runSqoop(Sqoop.java:183)
        at org.apache.sqoop.Sqoop.runTool(Sqoop.java:234)
        at org.apache.sqoop.Sqoop.runTool(Sqoop.java:243)
        at org.apache.sqoop.Sqoop.main(Sqoop.java:252)
```

问题原因：缺少依赖包

解决方式：下载对应mysql驱动包，并使用如下命令移动到`$SQOOP_HOME/lib/`目录下

```bash
mv mysql-connector-java-8.0.29.jar $SQOOP_HOME/lib/
```

### hadoop配置出错

```bash
Error: Could not find or load main class org.apache.hadoop.mapreduce.v2.app.MRAppMaster

Please check whether your <HADOOP_HOME>/etc/hadoop/mapred-site.xml contains the below configuration:
<property>
  <name>yarn.app.mapreduce.am.env</name>
  <value>HADOOP_MAPRED_HOME=${full path of your hadoop distribution directory}</value>
</property>
<property>
  <name>mapreduce.map.env</name>
  <value>HADOOP_MAPRED_HOME=${full path of your hadoop distribution directory}</value>
</property>
<property>
  <name>mapreduce.reduce.env</name>
  <value>HADOOP_MAPRED_HOME=${full path of your hadoop distribution directory}</value>
</property>
```

解决方式：编辑mapred-site.xml文件，添加以下配置后，重启Hadoop

```bash
  <property>
    <name>yarn.app.mapreduce.am.env</name>
    <value>HADOOP_MAPRED_HOME=/opt/hadoop-3.4.1/</value>
  </property>
  <property>
    <name>mapreduce.map.env</name>
    <value>HADOOP_MAPRED_HOME=/opt/hadoop-3.4.1/</value>
  </property>
  <property>
    <name>mapreduce.reduce.env</name>
    <value>HADOOP_MAPRED_HOME=/opt/hadoop-3.4.1/</value>
  </property>
```

## 总结

总之，Sqoop是一个非常实用的工具，可以帮助我们轻松地完成Hadoop和关系型数据库之间的数据传输。无论是将数据从关系型数据库中导入到Hadoop中进行分析，还是将数据从Hadoop中导出到关系型数据库中进行存储，都可以通过Sqoop来实现。

## 参考文档

[Sqoop入门（一篇就够了）-阿里云开发者社区](https://developer.aliyun.com/article/1046144)
