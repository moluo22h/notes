# Hadoop环境搭建指南

Hadoop是一个用于处理大规模数据集的分布式计算框架，具有高容错性、可伸缩性和可靠性。本文将向您介绍如何搭建Hadoop环境。

## Hadoop 环境搭建

### 1. 安装JDK

下载并解压 JDK ，推荐使用Java 8或更新版本。

```bash
wget https://download.java.net/openjdk/jdk8u44/ri/openjdk-8u44-linux-x64.tar.gz
tar -zxvf openjdk-8u44-linux-x64.tar.gz -C /opt/
```

使用`vi /etc/profile`命令配置环境变量。添加以下变量

```bash
export JAVA_HOME=/opt/java-se-8u44-ri
export CLASSPATH=.:$JAVA_HOME/lib:$JAVA_HOME/jre/lib
export PATH=$PATH:$JAVA_HOME/bin
```

保存文件后，运行以下命令使环境变量生效：

```bash
source /etc/profile
```

通过以下命令验证是否安装成功

```bash
# java -version
openjdk version "1.8.0_44"
OpenJDK Runtime Environment (build 1.8.0_44-b02)
OpenJDK 64-Bit Server VM (build 25.40-b25, mixed mode)
```

### 2. 安装Hadoop

下载并解压Hadoop，可从[官方网站](https://hadoop.apache.org/release.html)获取最新版本。其他下载地址：[Index of /hadoop/common (apache.org)](https://downloads.apache.org/hadoop/common/)

```bash
wget https://dlcdn.apache.org/hadoop/common/hadoop-3.4.1/hadoop-3.4.1.tar.gz
tar -zxvf hadoop-3.4.1.tar.gz -C /opt/
```

使用`vi /etc/profile`命令配置环境变量。添加以下变量：

```shell
export HADOOP_HOME=/opt/hadoop-3.4.1
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
```

保存文件后，运行以下命令使环境变量生效：

```shell
source /etc/profile
```

测试是否安装成功

```bash
# hadoop version
Hadoop 3.4.1
Source code repository https://github.com/apache/hadoop.git -r 4d7825309348956336b8f06a08322b78422849b1
Compiled by mthakur on 2024-10-09T14:57Z
Compiled on platform linux-x86_64
Compiled with protoc 3.23.4
From source with checksum 7292fe9dba5e2e44e3a9f763fce3e680
This command was run using /opt/hadoop-3.4.1/share/hadoop/common/hadoop-common-3.4.1.jar
```

## 配置Hadoop

Hadoop 的运行模式包括：`本地模式`、`伪分布式模式`、`完全分布式模式`。

本地模式为使用 `hdfs` 和 `yarn` ，完全分布式模式需要多台机器，伪分布式模式只需要一台机器且使用了`hdfs`和`yarn`，故本节我们以伪分布式模式为例

进入Hadoop的配置目录，下面的配置都将在该目录下完成

```shell
cd $HADOOP_HOME/etc/hadoop
```

### 1. 配置Hadoop环境变量

编辑`hadoop-env.sh`文件，将`JAVA_HOME`设置为您的JDK安装路径：

```shell
export JAVA_HOME=/opt/java-se-8u44-ri
```

### 2. 配置HDFS

HDFS 框架组成如下：

- NameNode（nn）： 存储文件的元数据，如文件名，文件目录结构，文件属性（生成时间、副本数、文件权限），以及每个文件的块所在的 DataNode 等。
- DataNode（dn）: 在本地文件系统存储文件块数据，以及块数据校验和。
- Secondary DataNode（2nn）： 用来监控 HDFS 状态的辅助后台程序，每隔一段时间获取 HDFS 元数据的快照。
  

编辑`core-site.xml`文件，添加以下配置：

```xml
 <!-- 指定HDFS中NameNode的地址 -->
<property>
  <name>fs.defaultFS</name>
  <value>hdfs://localhost:9000</value>
</property>

  <!-- （可选）指定Hadoop运行时产生文件的存储目录 -->
  <property>
    <name>hadoop.tmp.dir</name>
    <value>/opt/hadoop-3.4.1/data/tmp</value>
  </property>
```

编辑`hdfs-site.xml`文件，添加以下配置：

```xml
<!-- 指定HDFS副本的数量 -->
<property>
  <name>dfs.replication</name>
  <value>1</value>
</property>

<property>
  <name>dfs.namenode.name.dir</name>
  <value>file:///path/to/your/hadoop/data/dfs/name</value>
</property>

<property>
  <name>dfs.datanode.data.dir</name>
  <value>file:///path/to/your/hadoop/data/dfs/data</value>
</property>
```

初始化 NameNode，初始化HDFS的元数据：（仅第一次启动时初始化）

```shell
hdfs namenode -format
```

启动 NameNode和DataNode

```shell
hadoop-daemon.sh start namenode
hadoop-daemon.sh start datanode
```

> 提示：也可以直接使用组合命令启动 NameNode和DataNode：start-dfs.sh

查看是否启动成功

```bash
# jps
22953 NameNode
23131 DataNode
```

访问http://192.168.10.50:9870/，web 端查看 HDFS 文件系统

![image-20250324172336508](D:\user\person\notes\编程学习\大数据\assets\image-20250324172336508.png)

### 3. 配置YARN

- ResourceManager（RM）：
  - 处理客户端请求。
  - 监控 NodeManager。
  - 启动或监控 ApplicationMaster。
  - 资源的分配与调度。

- NodeManager（NM）：
  - 管理单个节点上的资源。
  - 处理来自 ResourceManager 的命令。
  - 处理来自 ApplicationMaster 的命令。
  - 资源的分配与调度。

- ApplicationMaster（AM）：
  - 负责数据的切分。
  - 为应用程序申请资源并分配给内部的任务。
  - 任务的监控与容错。

- Container：
  - Container 是 Yarn 中的资源抽象，它封装了某个节点上的多维度资源，如内存、CPU、磁盘、网络等。
    

编辑`yarn-site.xml`文件，添加以下配置：

```xml
<!-- Reducer获取数据的方式 -->
<property>
  <name>yarn.nodemanager.aux-services</name>
  <value>mapreduce_shuffle</value>
</property>
```

将 mapred-site.xml.template 重新命名为 mapred-site.xml

```xml
<!-- 指定MR运行在YARN上 -->
<property>
  <name>mapreduce.framework.name</name>
  <value>yarn</value>
</property>
```

启动 ResourceManager和NodeManager

```bash
yarn-daemon.sh start resourcemanager
yarn-daemon.sh start nodemanager
```

> 注意：启动前必须保证 NameNode 和 DataNode 已经启动
>
> 提示：也可以直接使用组合命令启动 start-yarn.sh

查看是否启动成功

```bash
# jps
24802 ResourceManager
25942 Jps
22953 NameNode
23131 DataNode
25085 NodeManager
```

访问http://192.168.10.50:8088/, web 端查看 YARN 页面

![image-20250324172919606](D:\user\person\notes\编程学习\大数据\assets\image-20250324172919606.png)

4. 配置历史服务器

   为了查看程序的历史运行情况，需要配置一下历史服务器。

   配置 mapred-site.xml，在该文件里面增加以下配置：

   ```bash
     <!-- (可选)历史服务器端地址 -->
     <property>
       <name>mapreduce.jobhistory.address</name>
       <value>localhost:10020</value>
     </property>
   
     <!-- (可选)历史服务器web端地址 -->
     <property>
        <name>mapreduce.jobhistory.webapp.address</name>
        <value>localhost:19888</value>
     </property>
   ```

   启动历史服务器

   ```bash
   mr-jobhistory-daemon.sh start historyserver
   ```

   查看历史服务器是否启动

   ```bash
   # jps
   25489 JobHistoryServer
   24802 ResourceManager
   25942 Jps
   22953 NameNode
   23131 DataNode
   25085 NodeManager
   ```

   访问http://192.168.10.50:19888/，查看web页面

   ![image-20250325090623309](D:\user\person\notes\编程学习\大数据\assets\image-20250325090623309.png)

## 常见问题

### 1. 伪分布式安装Hadoop

```bash
# hadoop-daemons.sh start namenode 
WARNING: Use of this script to start HDFS daemons is deprecated.
WARNING: Attempting to execute replacement "hdfs --workers --daemon start" instead.
localhost: Warning: Permanently added 'localhost' (ECDSA) to the list of known hosts.
localhost: Permission denied (publickey,gssapi-keyex,gssapi-with-mic).
```

报错原因：本机未设置ssh免密码登录本机（也就是说，ssh localhost的时候需要密码）此时会报错

```bash
# ssh localhost
Permission denied (publickey,gssapi-keyex,gssapi-with-mic).
```

解决方法：设置本机登录本机免密码即可（教程参照网上资料，大概逻辑为：服务端生成私钥和公钥，服务器端持有私钥，公钥交由客户端，此后客户端可免密码登录服务器端）

```bash
# 切换到~/.ssh目录下
cd ~/.ssh

# 在之后跳出的文字交互界面一路回车+yes即可
ssh-keygen -t rsa

# 将公钥追加到authorized_keys文件中去
cat id_rsa.pub >> authorized_keys

# 将authorized_keys文件权限更改为600
chmod 600 authorized_keys
```

至此设置免密操作完毕。完成后登录本机即为免密码，使用以下命令不再报错：

```bash
# ssh localhost
```

重新启动Hadoop，便可成功启动：

```bash
# hadoop-daemons.sh start namenode
WARNING: Use of this script to start HDFS daemons is deprecated.
WARNING: Attempting to execute replacement "hdfs --workers --daemon start" instead.
```

### 2. root用户启动报错

```bash
# start-all.sh 
Starting namenodes on [localhost]
ERROR: Attempting to operate on hdfs namenode as root
ERROR: but there is no HDFS_NAMENODE_USER defined. Aborting operation.

Starting datanodes
ERROR: Attempting to operate on hdfs datanode as root
ERROR: but there is no HDFS_DATANODE_USER defined. Aborting operation.

Starting secondary namenodes [hadoop]
ERROR: Attempting to operate on hdfs secondarynamenode as root
ERROR: but there is no HDFS_SECONDARYNAMENODE_USER defined. Aborting operation.

Starting resourcemanager
ERROR: Attempting to operate on yarn resourcemanager as root
ERROR: but there is no YARN_RESOURCEMANAGER_USER defined. Aborting operation.

Starting nodemanagers
ERROR: Attempting to operate on yarn nodemanager as root
ERROR: but there is no YARN_NODEMANAGER_USER defined. Aborting operation.
```

解决方案一：

输入如下命令，在环境变量中添加下面的配置

```bash
vi /etc/profile
```

然后向里面加入如下的内容

```bash
export HDFS_NAMENODE_USER=root
export HDFS_DATANODE_USER=root
export HDFS_SECONDARYNAMENODE_USER=root
export YARN_RESOURCEMANAGER_USER=root
export YARN_NODEMANAGER_USER=root
```

输入如下命令使改动生效

```bash
source /etc/profile
```

解决方案二：

将start-dfs.sh，stop-dfs.sh(在hadoop安装目录的sbin里)两个文件顶部添加以下参数

```ini
HDFS_DATANODE_USER=root
HADOOP_SECURE_DN_USER=hdfs
HDFS_NAMENODE_USER=root
HDFS_SECONDARYNAMENODE_USER=root
```

将start-yarn.sh，stop-yarn.sh(在hadoop安装目录的sbin里)两个文件顶部添加以下参数

```ini
YARN_RESOURCEMANAGER_USER=root
HADOOP_SECURE_DN_USER=yarn
YARN_NODEMANAGER_USER=root
```

修改完成后，将修改的配置文件copy到其他的节点

 ### 3. 无法远程连接

编辑`core-site.xml`文件，修改`hdfs://localhost:9000`配置为`hdfs://192.168.10.50:9000`

```xml
 <!-- 指定HDFS中NameNode的地址 -->
<property>
  <name>fs.defaultFS</name>
  <value>hdfs://192.168.10.50:9000</value>
</property>
```

> 注意：192.168.10.50是小编的ip，请根据实际情况更改

重启hadoop

## 结论

至此，您已成功搭建了Hadoop环境。您可以开始使用Hadoop来处理和分析大规模数据集了。祝您使用愉快！

> 注意：本文仅提供了基本的Hadoop环境搭建指南，具体的配置和调优取决于您的需求和环境。建议参考Hadoop官方文档和其他资源获取更多详细信息。

## 附录

hadoop 的启动和停止命令

```bash
# 启动所有的Hadoop守护进程。包括NameNode、 SecondaryNameNode、DataNode、ResourceManager、NodeManager
sbin/start-all.sh 

# 停止所有的Hadoop守护进程。包括NameNode、 SecondaryNameNode、DataNode、ResourceManager、NodeManager
sbin/stop-all.sh 
```

### hdfs相关命令

启动命令

```bash
# 启动Hadoop HDFS守护进程NameNode、SecondaryNameNode、DataNode
sbin/start-dfs.sh 

# 单独启动NameNode守护进程
sbin/hadoop-daemons.sh start namenode 
# 单独启动DataNode守护进程
sbin/hadoop-daemons.sh start datanode 
# 单独启动SecondaryNameNode守护进程
sbin/hadoop-daemons.sh start secondarynamenode 
```

停止命令

```bash
# 停止Hadoop HDFS守护进程NameNode、SecondaryNameNode和DataNode
sbin/stop-dfs.sh 

# 单独停止NameNode守护进程
sbin/hadoop-daemons.sh stop namenode
# 单独停止DataNode守护进程
sbin/hadoop-daemons.sh stop datanode
# 单独停止SecondaryNameNode守护进程
sbin/hadoop-daemons.sh stop secondarynamenode 
```

### yarn相关命令

启动命令

```bash
# 启动ResourceManager、NodeManager
sbin/start-yarn.sh

# 单独启动ResourceManager
sbin/yarn-daemon.sh start resourcemanager
# 单独启动NodeManager
sbin/yarn-daemons.sh start nodemanager

# 手动启动jobhistory
sbin/mr-jobhistory-daemon.sh start historyserver
```

停止命令

```bash
# 停止ResourceManager、NodeManager
sbin/stop-yarn.sh 

# 单独停止ResourceManager
sbin/yarn-daemon.sh stop resourcemanager 
# 单独停止NodeManager
sbin/yarn-daemons.sh stop nodemanager

# 手动停止jobhistory
sbin/mr-jobhistory-daemon.sh stop historyserver
```



## 参考文档

[Apache Hadoop 3.3.6 – Hadoop: Setting up a Single Node Cluster.](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html#Standalone_Operation)

[Hadoop 入门教程（超详细）_hadoop教程-CSDN博客](https://blog.csdn.net/weixin_42837961/article/details/105493561)
