创建虚拟空间

```bash
mkvirtualenv article_spider
```



创建一个scrapy项目

```bash
scrapy startproject AiticleSpider
```



scrapy目录结构

与项目同命的子文件夹包含`__init__.py`，items.py，piplines.py，settings.py等python文件

（1）`__init__.py`：此文件为项目的初始化文件，主要写的是一些项目的初始化信息。

（2）items.py：爬虫项目的数据容器文件，主要用来定义我们要获取的数据

（3）piplines.py：爬虫项目的管道文件，主要用来对items里面定义的数据进行进一步的加工与处理

（4）settings.py：爬虫项目的设置文件，主要为爬虫项目的一些设置信息

（5）spiders：文件夹此文件夹下放置的事爬虫项目中的爬虫部分相关



创建爬虫模板

```bash
scrapy genspider {爬虫名称} {网站域名}
```

```bash
scrapy genspider jobbole blog.jobbole.com
```

生成的模板如下

```python
# -*- coding: utf-8 -*-
import scrapy

class JobboleSpider(scrapy.Spider):
    name = 'jobbole'
    allowed_domains = ['blog.jobbole.com']
    start_urls = ['http://blog.jobbole.com/']

    def parse(self, response):
        pass
```

> 解析：start_urls为需要爬取url的列表



导入工程

导入工程文件

设置pycharm的配置，设计Project Interpreter为之前创建的虚拟环境article_spider